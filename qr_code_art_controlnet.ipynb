{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad83afe5",
   "metadata": {},
   "source": [
    "\n",
    "# üî≥ QR Code Art with Diffusion + ControlNet (Colab Ready)\n",
    "\n",
    "***Jungwoo Ahn***\n",
    "\n",
    "**Workflow:** Select model ‚Üí Set resolution ‚Üí Input link (+ optional image) ‚Üí Generate QR code ‚Üí ControlNet ‚Üí Output stylized, scannable QR art.\n",
    "\n",
    "**Included model combos (pick 1 at runtime):**\n",
    "1. **SDXL (High Quality)**: `stabilityai/stable-diffusion-xl-base-1.0` + **Canny ControlNet (SDXL)** ‚Äî great detail and fidelity.\n",
    "2. **SD1.5 + Canny (Reliable & Simple)**: `runwayml/stable-diffusion-v1-5` + `lllyasviel/sd-controlnet-canny` ‚Äî classic pipeline.\n",
    "3. **SD1.5 + QRCode-Monster (Specialized)**: `runwayml/stable-diffusion-v1-5` + `monster-labs/control_v1p_sd15_qrcode_monster` ‚Äî designed to preserve QR readability while stylizing.\n",
    "\n",
    "> The notebook supports **ControlNet conditioning** from the generated QR (edges or specialized QR ControlNet). You can also optionally feed a **style image** (image-to-image) to influence appearance while keeping the QR scannable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d04b5f",
   "metadata": {},
   "source": [
    "\n",
    "> **Tip (Colab):** Go to **Runtime ‚Üí Change runtime type ‚Üí GPU** for big speed-ups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72b2a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title ‚¨áÔ∏è Install dependencies\n",
    "!pip -q install --upgrade pip\n",
    "!pip -q install \"diffusers>=0.29.0\" transformers accelerate safetensors xformers\n",
    "!pip -q install opencv-python pillow qrcode[pil] numpy matplotlib ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b11284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title üì¶ Imports\n",
    "import os, io, math, time, random\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import qrcode\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "from diffusers import (\n",
    "    StableDiffusionXLControlNetPipeline,\n",
    "    StableDiffusionControlNetPipeline,\n",
    "    ControlNetModel,\n",
    "    AutoencoderKL,\n",
    "    DDIMScheduler,\n",
    "    DPMSolverMultistepScheduler,\n",
    ")\n",
    "\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "def show(img, title=None):\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.axis('off')\n",
    "    if title: plt.title(title)\n",
    "    plt.imshow(img if isinstance(img, np.ndarray) else np.array(img))\n",
    "    plt.show()\n",
    "\n",
    "def ensure_even(x:int)->int:\n",
    "    return int(x//8*8)  # most models like dims divisible by 8\n",
    "\n",
    "def to_pil(img: Image.Image | np.ndarray) -> Image.Image:\n",
    "    if isinstance(img, Image.Image):\n",
    "        return img.convert(\"RGB\")\n",
    "    return Image.fromarray(img).convert(\"RGB\")\n",
    "\n",
    "def make_qr(link:str, size:int=768, border:int=4) -> Image.Image:\n",
    "    qr = qrcode.QRCode(\n",
    "        version=None,  # automatic\n",
    "        error_correction=qrcode.constants.ERROR_CORRECT_H,  # robust after stylizing\n",
    "        box_size=10,\n",
    "        border=border,\n",
    "    )\n",
    "    qr.add_data(link)\n",
    "    qr.make(fit=True)\n",
    "    img = qr.make_image(fill_color=\"black\", back_color=\"white\").convert(\"RGB\")\n",
    "    img = img.resize((size, size), Image.NEAREST)\n",
    "    return img\n",
    "\n",
    "def canny_edges(img: Image.Image, low: int=100, high: int=200) -> Image.Image:\n",
    "    arr = np.array(img.convert(\"L\"))\n",
    "    edges = cv2.Canny(arr, low, high)\n",
    "    edges_rgb = np.stack([edges]*3, axis=-1)\n",
    "    return Image.fromarray(edges_rgb)\n",
    "\n",
    "def overlay_qr(alpha_img: Image.Image, qr_mask: Image.Image, alpha: float=0.25) -> Image.Image:\n",
    "    \"\"\"Optional: softly mix the raw QR onto the generated result to boost scan reliability.\"\"\"\n",
    "    a = np.array(alpha_img.convert(\"RGB\"), dtype=np.float32) / 255.0\n",
    "    q = np.array(qr_mask.convert(\"RGB\"), dtype=np.float32) / 255.0\n",
    "    # In QR, black modules are 0; we softly darken corresponding pixels\n",
    "    mixed = np.clip(a*(1.0) - (1.0-q)*alpha, 0, 1)\n",
    "    return Image.fromarray((mixed*255).astype(np.uint8))\n",
    "\n",
    "def save_image(img: Image.Image, path: str) -> str:\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    img.save(path)\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a498a6db",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee08ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title ‚öôÔ∏è Settings (edit these and run)\n",
    "#@markdown **Choose a model combo**\n",
    "MODEL_COMBO = \"SDXL + Canny (SDXL)\"  #@param [\"SDXL + Canny (SDXL)\", \"SD1.5 + Canny\", \"SD1.5 + QRCode-Monster\"]\n",
    "\n",
    "#@markdown **Resolution**\n",
    "RESOLUTION = \"768\"  #@param [\"512\", \"768\", \"1024\"]\n",
    "RESOLUTION = int(RESOLUTION)\n",
    "\n",
    "#@markdown **Your link (encoded into QR)**\n",
    "# LINK = \"https://example.com\"  #@param {type:\"string\"}\n",
    "LINK = \"https://github.com/jungwooahn721\"  #@param {type:\"string\"}\n",
    "\n",
    "#@markdown **Optional style image URL or upload path (leave empty if none)**\n",
    "STYLE_IMAGE_URL_OR_PATH = \"\"  #@param {type:\"string\"}\n",
    "\n",
    "#@markdown **Prompt / Negative prompt**\n",
    "PROMPT = \"a vibrant, futuristic cyberpunk poster, neon glow, high detail, symmetrical balance\"  #@param {type:\"string\"}\n",
    "NEGATIVE_PROMPT = \"blurry, low quality, distorted, extra text, artifacts\"  #@param {type:\"string\"}\n",
    "\n",
    "#@markdown **Sampler steps & strength (if using style init image)**\n",
    "NUM_STEPS = 25  #@param {type:\"slider\", min:1, max:50, step:1}\n",
    "GUIDANCE_SCALE = 5.0  #@param {type:\"slider\", min:0.0, max:15.0, step:0.5}\n",
    "INIT_IMAGE_STRENGTH = 0.35  #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
    "\n",
    "#@markdown **Canny thresholds (if using canny control)**\n",
    "CANNY_LOW = 100  #@param {type:\"slider\", min:0, max:255, step:1}\n",
    "CANNY_HIGH = 200  #@param {type:\"slider\", min:0, max:255, step:1}\n",
    "\n",
    "#@markdown **Seed (set -1 for random)**\n",
    "SEED = -1  #@param {type:\"number\"}\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d201283",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title üß† Load model(s)\n",
    "import torch\n",
    "\n",
    "torch_dtype = torch.float16 if (device==\"cuda\") else torch.float32\n",
    "\n",
    "if MODEL_COMBO == \"SDXL + Canny (SDXL)\":\n",
    "    base_model = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "    controlnet_id = \"diffusers/controlnet-canny-sdxl-1.0\"  # SDXL ControlNet (canny)\n",
    "    controlnet = ControlNetModel.from_pretrained(controlnet_id, torch_dtype=torch_dtype)\n",
    "    pipe = StableDiffusionXLControlNetPipeline.from_pretrained(\n",
    "        base_model,\n",
    "        controlnet=controlnet,\n",
    "        torch_dtype=torch_dtype,\n",
    "        variant=\"fp16\" if torch_dtype==torch.float16 else None,\n",
    "        use_safetensors=True,\n",
    "    )\n",
    "    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "    if device == \"cpu\":\n",
    "        pipe.enable_model_cpu_offload()\n",
    "    else:\n",
    "        pipe.to(device)\n",
    "\n",
    "elif MODEL_COMBO == \"SD1.5 + Canny\":\n",
    "    base_model = \"runwayml/stable-diffusion-v1-5\"\n",
    "    controlnet_id = \"lllyasviel/sd-controlnet-canny\"\n",
    "    controlnet = ControlNetModel.from_pretrained(controlnet_id, torch_dtype=torch_dtype)\n",
    "    pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "        base_model,\n",
    "        controlnet=controlnet,\n",
    "        torch_dtype=torch_dtype,\n",
    "        safety_checker=None,\n",
    "        feature_extractor=None,\n",
    "        use_safetensors=True,\n",
    "    )\n",
    "    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "    try:\n",
    "        pipe.enable_xformers_memory_efficient_attention()\n",
    "    except Exception as _:\n",
    "        pass\n",
    "    if device == \"cpu\":\n",
    "        pipe.enable_model_cpu_offload()\n",
    "    else:\n",
    "        pipe.to(device)\n",
    "\n",
    "elif MODEL_COMBO == \"SD1.5 + QRCode-Monster\":\n",
    "    base_model = \"runwayml/stable-diffusion-v1-5\"\n",
    "    controlnet_id = \"monster-labs/control_v1p_sd15_qrcode_monster\"  # specialized QR ControlNet\n",
    "    controlnet = ControlNetModel.from_pretrained(controlnet_id, torch_dtype=torch_dtype)\n",
    "    pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "        base_model,\n",
    "        controlnet=controlnet,\n",
    "        torch_dtype=torch_dtype,\n",
    "        safety_checker=None,\n",
    "        feature_extractor=None,\n",
    "        use_safetensors=True,\n",
    "    )\n",
    "    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "    try:\n",
    "        pipe.enable_xformers_memory_efficient_attention()\n",
    "    except Exception as _:\n",
    "        pass\n",
    "    if device == \"cpu\":\n",
    "        pipe.enable_model_cpu_offload()\n",
    "    else:\n",
    "        pipe.to(device)\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Unknown MODEL_COMBO selection.\")\n",
    "\n",
    "print(\"Loaded:\", MODEL_COMBO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09117098",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title üß© Generate QR (and optional style image)\n",
    "W = H = ensure_even(RESOLUTION)\n",
    "\n",
    "qr_img = make_qr(LINK, size=W, border=4)\n",
    "show(qr_img, \"Raw QR (high error correction)\")\n",
    "\n",
    "style_img = None\n",
    "if STYLE_IMAGE_URL_OR_PATH.strip():\n",
    "    try:\n",
    "        if STYLE_IMAGE_URL_OR_PATH.startswith(\"http\"):\n",
    "            style_img = load_image(STYLE_IMAGE_URL_OR_PATH)\n",
    "        else:\n",
    "            style_img = Image.open(STYLE_IMAGE_URL_OR_PATH)\n",
    "        style_img = style_img.convert(\"RGB\").resize((W, H))\n",
    "        show(style_img, \"Style image (resized)\")\n",
    "    except Exception as e:\n",
    "        print(\"Failed to load style image:\", e)\n",
    "        style_img = None\n",
    "\n",
    "# Control image (Canny or QR-specialized)\n",
    "if MODEL_COMBO in [\"SDXL + Canny (SDXL)\", \"SD1.5 + Canny\"]:\n",
    "    control_img = canny_edges(qr_img, CANNY_LOW, CANNY_HIGH)\n",
    "    show(control_img, \"ControlNet condition (Canny edges from QR)\")\n",
    "else:\n",
    "    # QRCode-Monster expects the raw QR silhouette as control (binary-ish)\n",
    "    control_img = qr_img\n",
    "    show(control_img, \"ControlNet condition (raw QR)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02046b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title üé® Generate QR code art\n",
    "g_seed = SEED if SEED >= 0 else random.randint(0, 2**32-1)\n",
    "generator = torch.Generator(device=device).manual_seed(g_seed)\n",
    "print(\"Seed:\", g_seed)\n",
    "\n",
    "common_kwargs = dict(\n",
    "    prompt=PROMPT,\n",
    "    negative_prompt=NEGATIVE_PROMPT,\n",
    "    num_inference_steps=NUM_STEPS,\n",
    "    guidance_scale=GUIDANCE_SCALE,\n",
    "    generator=generator,\n",
    ")\n",
    "\n",
    "if MODEL_COMBO.startswith(\"SDXL\"):\n",
    "    # SDXL ControlNet expects image/control_image; optional 'image' for img2img via 'strength'\n",
    "    if style_img is not None:\n",
    "        out = pipe(\n",
    "            **common_kwargs,\n",
    "            image=style_img,           # SDXL img2img support\n",
    "            strength=INIT_IMAGE_STRENGTH,\n",
    "            control_image=control_img.resize((W,H)),\n",
    "            width=W,\n",
    "            height=H,\n",
    "        )\n",
    "    else:\n",
    "        out = pipe(\n",
    "            **common_kwargs,\n",
    "            control_image=control_img.resize((W,H)),\n",
    "            width=W,\n",
    "            height=H,\n",
    "        )\n",
    "else:\n",
    "    # SD1.5 ControlNet pipeline (txt2img or img2img-like with init_image)\n",
    "    if style_img is not None:\n",
    "        out = pipe(\n",
    "            **common_kwargs,\n",
    "            image=style_img,\n",
    "            control_image=control_img.resize((W,H)),\n",
    "            strength=INIT_IMAGE_STRENGTH,\n",
    "        )\n",
    "    else:\n",
    "        out = pipe(\n",
    "            **common_kwargs,\n",
    "            control_image=control_img.resize((W,H)),\n",
    "            width=W,\n",
    "            height=H,\n",
    "        )\n",
    "\n",
    "gen = out.images[0]\n",
    "\n",
    "# Optional: softly re-impose the QR modules for maximum scan reliability\n",
    "final_img = overlay_qr(gen, qr_img, alpha=0.20)\n",
    "\n",
    "show(gen, \"Generated (pre-overlay)\")\n",
    "show(final_img, \"Final (soft QR overlay for reliability)\")\n",
    "\n",
    "save_dir = \"/content\" if os.path.isdir(\"/content\") else \"/mnt/data\"\n",
    "raw_path = save_image(gen, os.path.join(save_dir, f\"qr_art_raw_{g_seed}.png\"))\n",
    "final_path = save_image(final_img, os.path.join(save_dir, f\"qr_art_final_{g_seed}.png\"))\n",
    "qr_path = save_image(qr_img, os.path.join(save_dir, f\"qr_raw_{g_seed}.png\"))\n",
    "print(\"Saved:\")\n",
    "print(\" -\", qr_path)\n",
    "print(\" -\", raw_path)\n",
    "print(\" -\", final_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9789362",
   "metadata": {},
   "source": [
    "\n",
    "## ‚úÖ Tips for Scannability\n",
    "- Keep **error correction H** (already set) for robustness.\n",
    "- Prefer **high contrast** between QR modules and background after stylizing.\n",
    "- Use **Canny thresholds** that preserve square modules (100/200 is a good start).\n",
    "- If scans fail, **increase overlay alpha** (in code) or reduce `INIT_IMAGE_STRENGTH` (if using style image).\n",
    "\n",
    "## Prompting Hints\n",
    "- Keep compositions **balanced/symmetric**; avoid heavy warping.\n",
    "- Add keywords like *\"clean edges, crisp geometry, high contrast, centered, minimal clutter\"*.\n",
    "- For SDXL, quality tags like *\"photorealistic, sharp details, 8k\"* can help, but don't overdo it.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
